{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c25e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import psycopg2 # pip install psycopg2\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb24655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean raw_seasons.json data & convert to csv\n",
    "\n",
    "with open('./data/raw_seasons.json', encoding=\"utf-8\") as file:\n",
    "    seasons = json.load(file)\n",
    "\n",
    "# csv headers\n",
    "seasons_data = [[\"seasonID\",\"seasonYear\",\"startDate\",\"endDate\",\"leagueName\",\"leagueType\",\"leagueCountry\"]]\n",
    "    \n",
    "for season in seasons:\n",
    "    seasons_data.append([\n",
    "        season[\"seasonID\"],\n",
    "        season[\"year\"], \n",
    "        season[\"start\"], \n",
    "        season[\"end\"],\n",
    "        season[\"name\"],\n",
    "        season[\"type\"],\n",
    "        season[\"country\"]\n",
    "    ])\n",
    "    \n",
    "with open('./data/cleaned_seasons.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(seasons_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6b9fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert cleaned_seasons.csv data into db\n",
    "\n",
    "# connect to db\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# before move data to public, because of access rights\n",
    "sql = '''COPY Season(seasonID,seasonYear,startDate,endDate,leagueName,leagueType,leagueCountry)\n",
    "FROM 'C:/Users/Public/cleaned_seasons.csv'\n",
    "DELIMITER ','\n",
    "CSV HEADER;'''\n",
    "\n",
    "cursor.execute(sql)\n",
    "\n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "757a117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to check if birthdate of player is a valid birthdate\n",
    "\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "\n",
    "def is_valid_birthdate(birthdate):\n",
    "    # Split the birthdate into its components\n",
    "    year, month, day = map(int, birthdate.split('-'))\n",
    "\n",
    "    # Check that the month is between 1 and 12, and the day is between 1 and the number of days in the month\n",
    "    if not (1 <= month <= 12) or not (1 <= day <= calendar.monthrange(year, month)[1]):\n",
    "        return False\n",
    "\n",
    "    # Check that the year is not in the future\n",
    "    current_year = datetime.now().year\n",
    "    if year > current_year:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def is_valid_primary_keys(playerId, firstname, lastname, birthdate):\n",
    "    values = [playerId, firstname, lastname, birthdate]\n",
    "    # if all values are not None, return True\n",
    "    return all(value is not None for value in values)\n",
    "\n",
    "def is_duplicate(firstname, lastname, birthdate, dictionary):\n",
    "    key = firstname + lastname + birthdate\n",
    "    if key in dictionary:\n",
    "        return True # duplicate found\n",
    "    return False\n",
    "\n",
    "def manipulate_wh(weightInput, heightInput):\n",
    "    weight, height = weightInput, heightInput\n",
    "     # give weight and height zero value if null\n",
    "    if weight is not None:\n",
    "        weight_str = weight.strip()\n",
    "        if weight_str != \"\":\n",
    "            weight = int(weight.replace(\"kg\", \"\"))\n",
    "        else:\n",
    "            weight = 0\n",
    "    else:\n",
    "        weight = 0\n",
    "    if height is not None:\n",
    "        height_str = height.strip()\n",
    "        if height_str != \"\":\n",
    "            height = int(height.replace(\"cm\", \"\"))\n",
    "        else:\n",
    "            height = 0\n",
    "    else:\n",
    "        height = 0\n",
    "        \n",
    "    return weight, height\n",
    "\n",
    "def is_valid_primary_keys_stats(playerId, seasonId, teamId):\n",
    "    values = [playerId, seasonId, teamId]\n",
    "    # if all values are not None, return True\n",
    "    return all(value is not None for value in values)\n",
    "\n",
    "def is_duplicate_stats(playerId, seasonId, teamId, dictionary):\n",
    "    key = str(playerId) + str(seasonId) + str(teamId)\n",
    "    if key in dictionary:\n",
    "        return True # duplicate found\n",
    "    return False\n",
    "\n",
    "def check_string(arr, toCheck = \"\\n    \"):\n",
    "    values = arr\n",
    "    for i in range(len(values)):\n",
    "        if values[i] == toCheck:\n",
    "            values[i] = None\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2efb1f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped players due to not tidy data:  78174\n",
      "Skipped stats due to not tidy data:  9538\n"
     ]
    }
   ],
   "source": [
    "# clean raw_players.json data & convert to csv\n",
    "\n",
    "# raw players (with statistics) file\n",
    "with open('./data/raw_players.json', encoding=\"utf8\") as file:\n",
    "    players = json.load(file)\n",
    "\n",
    "# csv headers\n",
    "players_data = [[\"playerID\",\"firstname\",\"lastname\",\"birthDate\",\"heightCm\",\"weightKg\",\"nationality\"]]\n",
    "stats_data = [[\n",
    "    \"playerID\",\"seasonID\",\"teamID\",\"teamName\",\"gamesAppearances\", \n",
    "    \"gamesLineups\",\"gamesMinutes\",\"gamesPosition\",\"gamesCaptain\", \n",
    "    \"gamesRating\",\"goalsTotal\",\"goalsConceded\",\"goalsAssists\",\n",
    "    \"goalsSaved\",\"tacklesTotal\",\"tacklesBlocks\",\"tacklesInterceptions\", \n",
    "    \"foulsDrawn\",\"foulsCommited\",\"passesKey\",\"passesTotal\",\"passesAccuracy\", \n",
    "    \"duelsWon\",\"duelsTotal\",\"cardRed\",\"cardYellow\",\"cardYellowred\",\"shotsTotal\",\n",
    "    \"shotsOn\",\"dribblesAttempts\", \"dribblesSuccess\",\"dribblesPast\",\"penaltyWon\", \n",
    "    \"penaltyCommited\",\"penaltyScored\",\"penaltyMissed\",\"penaltySaved\",\n",
    "    \"substituesIn\", \"substitutesOut\",\"substitutesBench\"]]\n",
    "playsIn_data = [[\"playerID\", \"seasonID\"]]\n",
    "\n",
    "# hash table\n",
    "players_dict = {}\n",
    "\n",
    "skipped_players = 0\n",
    "skipped_stats = 0\n",
    "\n",
    "for player in players:\n",
    "    playerId, seasonId, firstname, lastname, birthdate, statistics = player[\"player\"][\"id\"], player[\"seasonID\"], player[\"player\"][\"firstname\"], player[\"player\"][\"lastname\"], player[\"player\"][\"birth\"][\"date\"], player[\"statistics\"]\n",
    "    \n",
    "    # add players only if they have an id, firstname, lastname and a birthday\n",
    "    if not is_valid_primary_keys(playerId, firstname, lastname, birthdate):\n",
    "        skipped_players += 1\n",
    "        continue\n",
    "    \n",
    "    # don't add add players without a valid birthday\n",
    "    if not is_valid_birthdate(birthdate):\n",
    "        skipped_players += 1\n",
    "        continue\n",
    "        \n",
    "    # append player only if no duplcate found, append stats anyway\n",
    "    if not is_duplicate(firstname, lastname, birthdate, players_dict):\n",
    "        # manipulate weight and height\n",
    "        weight, height = manipulate_wh(player[\"player\"][\"weight\"], player[\"player\"][\"height\"])\n",
    "\n",
    "        # append to final players data\n",
    "        players_data.append([\n",
    "            playerId,\n",
    "            firstname, \n",
    "            lastname, \n",
    "            birthdate,\n",
    "            height,\n",
    "            weight,\n",
    "            player[\"player\"][\"nationality\"]\n",
    "        ])\n",
    "\n",
    "        # append key to players_dict to check in next iteration if duplicate\n",
    "        player_key = firstname + lastname + birthdate\n",
    "        players_dict[player_key] = True\n",
    "        players_dict[playerId] = True # Foreign Key Constraint\n",
    "\n",
    "        # append to final playsIn data\n",
    "        playsIn_data.append([\n",
    "            playerId,\n",
    "            seasonId, \n",
    "        ])\n",
    "    else:\n",
    "        if playerId in players_dict:\n",
    "            # append in playsIn otherwise playsIn only with one playerid record\n",
    "            playsIn_data.append([\n",
    "                playerId,\n",
    "                seasonId, \n",
    "            ])\n",
    "        \n",
    "    # if stats are not empty or not valid continue\n",
    "    temp_stats_dict = {}\n",
    "    for stats in statistics:\n",
    "        if not is_valid_primary_keys_stats(playerId, seasonId, stats[\"team\"][\"id\"]):\n",
    "            skipped_stats += 1\n",
    "            continue\n",
    "        if is_duplicate_stats(playerId, seasonId, stats[\"team\"][\"id\"], temp_stats_dict):\n",
    "            skipped_stats += 1\n",
    "            continue\n",
    "            \n",
    "        # if player is not added to players data / foreign key constraint skip stats\n",
    "        player_key = firstname + lastname + birthdate\n",
    "        if not (player_key in players_dict):\n",
    "            skipped_stats += 1\n",
    "            continue\n",
    "            \n",
    "        if not (playerId in players_dict):\n",
    "            skipped_stats += 1\n",
    "            continue\n",
    "            \n",
    "        # append key to temp stats to check in next iteration if duplicate\n",
    "        stats_key = str(playerId) + str(seasonId) + str(stats[\"team\"][\"id\"])\n",
    "        temp_stats_dict[stats_key] = True\n",
    "        \n",
    "        data = [\n",
    "            playerId,\n",
    "            seasonId, \n",
    "            stats[\"team\"][\"id\"], \n",
    "            stats[\"team\"][\"name\"],\n",
    "            stats[\"games\"][\"appearences\"],\n",
    "            stats[\"games\"][\"lineups\"],\n",
    "            stats[\"games\"][\"minutes\"],\n",
    "            stats[\"games\"][\"position\"], \n",
    "            stats[\"games\"][\"captain\"], \n",
    "            stats[\"games\"][\"rating\"],\n",
    "            stats[\"goals\"][\"total\"], \n",
    "            stats[\"goals\"][\"conceded\"], \n",
    "            stats[\"goals\"][\"assists\"], \n",
    "            stats[\"goals\"][\"saves\"], \n",
    "            stats[\"tackles\"][\"total\"], \n",
    "            stats[\"tackles\"][\"blocks\"],\n",
    "            stats[\"tackles\"][\"interceptions\"], \n",
    "            stats[\"fouls\"][\"drawn\"], \n",
    "            stats[\"fouls\"][\"committed\"], \n",
    "            stats[\"passes\"][\"key\"], \n",
    "            stats[\"passes\"][\"total\"],\n",
    "            stats[\"passes\"][\"accuracy\"], \n",
    "            stats[\"duels\"][\"won\"], \n",
    "            stats[\"duels\"][\"total\"], \n",
    "            stats[\"cards\"][\"red\"], \n",
    "            stats[\"cards\"][\"yellow\"], \n",
    "            stats[\"cards\"][\"yellowred\"],\n",
    "            stats[\"shots\"][\"total\"], \n",
    "            stats[\"shots\"][\"on\"], \n",
    "            stats[\"dribbles\"][\"attempts\"], \n",
    "            stats[\"dribbles\"][\"success\"], \n",
    "            stats[\"dribbles\"][\"past\"],\n",
    "            stats[\"penalty\"][\"won\"], \n",
    "            stats[\"penalty\"][\"commited\"], \n",
    "            stats[\"penalty\"][\"scored\"], \n",
    "            stats[\"penalty\"][\"missed\"], \n",
    "            stats[\"penalty\"][\"saved\"],\n",
    "            stats[\"substitutes\"][\"in\"], \n",
    "            stats[\"substitutes\"][\"out\"], \n",
    "            stats[\"substitutes\"][\"bench\"],\n",
    "        ]\n",
    "        \n",
    "        # check if values include \"\\n    \"\n",
    "        stats_values = check_string(data)\n",
    "        \n",
    "        # append to final stats data\n",
    "        stats_data.append(stats_values)\n",
    "        \n",
    "print(\"Skipped players due to not tidy data: \", skipped_players)\n",
    "print(\"Skipped stats due to not tidy data: \", skipped_stats)\n",
    "\n",
    "with open('./data/cleaned_players.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(players_data)\n",
    "    \n",
    "with open('./data/cleaned_statistics.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(stats_data)\n",
    "    \n",
    "with open('./data/cleaned_playsIn.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(playsIn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38540079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert cleaned_players.csv data into db\n",
    "\n",
    "# connect to db\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# move data to public, because of access rights (ON CONFLICT clause is only available in PostgreSQL 9.5 and later)\n",
    "sql = '''COPY Player(playerID,firstname,lastname,birthDate,heightCm,weightKg,nationality)\n",
    "FROM 'C:/Users/Public/cleaned_players.csv'\n",
    "DELIMITER ','\n",
    "ENCODING 'UTF8'\n",
    "CSV HEADER;'''\n",
    "\n",
    "try:\n",
    "    cursor.execute(sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0157ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert cleaned_playsIn.csv data into db\n",
    "\n",
    "# connect to db\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# move data to public, because of access rights (ON CONFLICT clause is only available in PostgreSQL 9.5 and later)\n",
    "sql = '''COPY playsIn(playerID, seasonID)\n",
    "FROM 'C:/Users/Public/cleaned_playsIn.csv'\n",
    "DELIMITER ','\n",
    "ENCODING 'UTF8'\n",
    "CSV HEADER;'''\n",
    "\n",
    "try:\n",
    "    cursor.execute(sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "620093fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert cleaned_statistics.csv data into db\n",
    "\n",
    "# connect to db\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# move data to public, because of access rights (ON CONFLICT clause is only available in PostgreSQL 9.5 and later)\n",
    "sql = '''COPY Statistics(playerID,seasonID,teamID,teamName,gamesAppearances,gamesLineups,gamesMinutes,gamesPosition,gamesCaptain,gamesRating,goalsTotal,goalsConceded,goalsAssists,\n",
    "goalsSaved,tacklesTotal,tacklesBlocks,tacklesInterceptions,foulsDrawn,foulsCommited,passesKey,passesTotal,passesAccuracy,duelsWon,duelsTotal,cardRed,cardYellow,cardYellowred,shotsTotal,\n",
    "shotsOn,dribblesAttempts,dribblesSuccess,dribblesPast,penaltyWon,penaltyCommited,penaltyScored,penaltyMissed,penaltySaved,substituesIn,substitutesOut,substitutesBench)\n",
    "FROM 'C:/Users/Public/cleaned_statistics.csv'\n",
    "DELIMITER ','\n",
    "ENCODING 'UTF8'\n",
    "CSV HEADER;'''\n",
    "\n",
    "try:\n",
    "    cursor.execute(sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b3fd314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# further helper functions\n",
    "def transform_birthdate(bday):\n",
    "    if bday == None:\n",
    "        return \"3000-01-01\" # return invalid birthdate\n",
    "    return bday[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "244bded0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of cards json data:  1024204\n",
      "Skipped cards due to not tidy data:  1\n",
      "Total cards:  1024204\n",
      "Matched cards:  502275\n",
      "Not appended cards due to not matched data:  521929\n"
     ]
    }
   ],
   "source": [
    "# 1. Matching: Match cards with primary keys firstname, lastname and birthdate\n",
    "\n",
    "with open('./data/raw_sorare_all_cards.json', encoding=\"utf8\") as file:\n",
    "    cards = json.load(file)\n",
    "    \n",
    "# csv headers\n",
    "cards_data = [[\"assetID\",\"rarity\",\"seasonYear\",\"birthDate\",\"bestFoot\",\"firstName\",\"lastName\", \"shirtNumber\"]]\n",
    "not_appended_cards_data = []\n",
    "\n",
    "# hash tables to check for duplicates\n",
    "cards_dict = {}\n",
    "\n",
    "# helper to count\n",
    "skipped_cards = 0\n",
    "\n",
    "\n",
    "print(\"Length of cards json data: \", len(cards))\n",
    "for card in cards:\n",
    "    assetId, firstname, lastname, birthdate = card[\"assetId\"], card[\"player\"][\"firstName\"], card[\"player\"][\"lastName\"], card[\"player\"][\"birthDate\"]\n",
    "    \n",
    "    # add players only if they have an id, firstname, lastname and a birthday\n",
    "    if not is_valid_primary_keys(assetId, firstname, lastname, birthdate):\n",
    "        skipped_cards += 1\n",
    "        continue\n",
    "    \n",
    "    # transform & check birthdate\n",
    "    birthdate = transform_birthdate(birthdate)\n",
    "    if not is_valid_birthdate(birthdate):\n",
    "        skipped_cards += 1\n",
    "        continue\n",
    "        \n",
    "    # don't add duplicates\n",
    "    if assetId in cards_dict:\n",
    "        skipped_cards += 1\n",
    "        continue\n",
    "        \n",
    "    # foreign key constraint\n",
    "    player_key = firstname + lastname + birthdate #from cards\n",
    "    if player_key in players_dict: # match\n",
    "        cards_data.append([\n",
    "            card[\"assetId\"],\n",
    "            card[\"rarity\"],\n",
    "            card[\"season\"][\"startYear\"],\n",
    "            birthdate,\n",
    "            card[\"player\"][\"bestFoot\"],\n",
    "            firstname,\n",
    "            lastname,\n",
    "            card[\"player\"][\"shirtNumber\"]\n",
    "        ])\n",
    "        cards_dict[card[\"assetId\"]] = True # to check for duplicates (here & later on)\n",
    "    else: # no match\n",
    "        not_appended_cards_data.append([\n",
    "            card[\"assetId\"],\n",
    "            card[\"rarity\"],\n",
    "            card[\"season\"][\"startYear\"],\n",
    "            birthdate,\n",
    "            card[\"player\"][\"bestFoot\"],\n",
    "            firstname,\n",
    "            lastname,\n",
    "            card[\"player\"][\"shirtNumber\"],\n",
    "            card[\"player\"][\"weight\"],\n",
    "            card[\"player\"][\"height\"]\n",
    "        ])\n",
    "        \n",
    "\n",
    "print(\"Skipped cards due to not tidy data: \", skipped_cards)\n",
    "print(\"Total cards: \", len(cards_data) + len(not_appended_cards_data))\n",
    "print(\"Matched cards: \", len(cards_data))\n",
    "print(\"Not appended cards due to not matched data: \", len(not_appended_cards_data))    \n",
    "\n",
    "with open('./data/cleaned_cards_1.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(cards_data)\n",
    "    \n",
    "with open('./data/cleaned_not_appended_cards_1.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(not_appended_cards_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6495242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert 1. Match cleaned_cards_1.csv data into db\n",
    "\n",
    "# connect to db\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# move data to public, because of access rights (ON CONFLICT clause is only available in PostgreSQL 9.5 and later)\n",
    "sql = '''COPY Card(assetID,rarity,seasonYear,birthDate,bestFoot,firstName,lastName,shirtNumber)\n",
    "FROM 'C:/Users/Public/cleaned_cards_1.csv'\n",
    "DELIMITER ','\n",
    "ENCODING 'UTF8'\n",
    "CSV HEADER;'''\n",
    "\n",
    "try:\n",
    "    cursor.execute(sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c5b752f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of players that are not matched as cards:  5626\n",
      "with a total of no of rows that are not matched:  521929\n"
     ]
    }
   ],
   "source": [
    "# create hash table with not appended cards\n",
    "not_appended_cards_dict = {}\n",
    "for card in not_appended_cards_data:\n",
    "    assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "    player_key = firstname + lastname + birthdate\n",
    "    if player_key in not_appended_cards_dict:\n",
    "        not_appended_cards_dict[player_key].append((assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height))\n",
    "    else:\n",
    "        not_appended_cards_dict[player_key] = [(assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height)]\n",
    "        \n",
    "print(\"No of players that are not matched as cards: \", len(not_appended_cards_dict))\n",
    "print(\"with a total of no of rows that are not matched: \", len(not_appended_cards_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e2c3bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper\n",
    "\n",
    "def is_valid_elements(birthdate, weight, height):\n",
    "    values = [birthdate, weight, height]\n",
    "    # if all values are not None, return True\n",
    "    return all(value is not None for value in values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fe971f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Players without valid elements:  1831\n",
      "Players without results in players table:  1462\n",
      "These player can potentially be matched:  3293  with a total no of rows:  299998\n",
      "******************\n",
      "Players (rows) that are matched, but already in cards table (no action required):  3\n",
      "******************\n",
      "Players that couldn't be matched, because there at least two players with same birthdate, weight & height:  95\n",
      "with total rows that could still be matched with other methods:  9026\n",
      "******************\n",
      "Players that are now matched:  2238\n",
      "with new added total rows of:  212903\n",
      "******************\n",
      "At this point we matched from a total of  715178  rows.\n"
     ]
    }
   ],
   "source": [
    "# 2. Matching: Match cards with birthdate, weight and height\n",
    "# Assumption/Idea: A professionel player has a sorare card with correct weight, height and birthdate. This information should also be the same in our player table\n",
    "\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cards_data_v2 = [[\"assetID\",\"rarity\",\"seasonYear\",\"birthDate\",\"bestFoot\",\"firstName\",\"lastName\", \"shirtNumber\"]]\n",
    "not_appended_cards_data_v2 = [] # cards that still are not going to be appended\n",
    "potential_appendable_cards_data = []\n",
    "\n",
    "new_cards_dict = dict(cards_dict) # to check for duplicates in play\n",
    "\n",
    "# helper to count\n",
    "not_valid_elements = 0\n",
    "duplicate_found_rows = 0\n",
    "r0 = 0\n",
    "r1 = 0\n",
    "r2 = 0\n",
    "\n",
    "\n",
    "for key, value in not_appended_cards_dict.items():\n",
    "    assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = value[0][0], value[0][1], value[0][2], value[0][3], value[0][4], value[0][5], value[0][6], value[0][7], value[0][8], value[0][9]\n",
    "\n",
    "    # if one of the values are null, don't query it\n",
    "    if not is_valid_elements(birthdate, weight, height):\n",
    "        for card in value:\n",
    "            assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "            not_appended_cards_data_v2.append([\n",
    "                assetId,\n",
    "                rarity,\n",
    "                seasonYear,\n",
    "                birthdate,\n",
    "                bestFoot,\n",
    "                firstname,\n",
    "                lastname,\n",
    "                shirtNumber,\n",
    "                weight,\n",
    "                height\n",
    "            ])\n",
    "        not_valid_elements += 1\n",
    "        continue\n",
    "    \n",
    "    # make sql statement (assumpiton: professional player, weight and height match)\n",
    "    query = \"SELECT * FROM Player WHERE birthdate = %s AND weightkg = %s AND heightcm = %s\"\n",
    "    cursor.execute(query, (birthdate, weight, height))\n",
    "    results = cursor.fetchall()\n",
    "    \n",
    "    # if we couldn't find player in our players table with same birthdate, height & weight\n",
    "    if len(results) == 0:\n",
    "        for card in value:\n",
    "            assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "            not_appended_cards_data_v2.append([\n",
    "                assetId,\n",
    "                rarity,\n",
    "                seasonYear,\n",
    "                birthdate,\n",
    "                bestFoot,\n",
    "                firstname,\n",
    "                lastname,\n",
    "                shirtNumber,\n",
    "                weight,\n",
    "                height\n",
    "            ])\n",
    "        r0 += 1\n",
    "        continue\n",
    "    \n",
    "    # perfect match\n",
    "    if len(results) == 1:\n",
    "        temp_r1 = 0\n",
    "        for card in value:\n",
    "            assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "            \n",
    "            # don't add duplicates\n",
    "            if assetId in new_cards_dict:\n",
    "                duplicate_found_rows += 1\n",
    "            else:\n",
    "                cards_data_v2.append([\n",
    "                    assetId,\n",
    "                    rarity,\n",
    "                    seasonYear,\n",
    "                    birthdate, # birthdate must be correct, coz of query - foreign key constrain\n",
    "                    bestFoot,\n",
    "                    results[0][1], # use firstname from players table (source of truth) - foreign key constrain\n",
    "                    results[0][2], # use lastname from players table (source of truth) - foreign key constrain\n",
    "                    shirtNumber\n",
    "                ])\n",
    "\n",
    "                new_cards_dict[assetId] = True\n",
    "                temp_r1 += 1\n",
    "        if temp_r1 > 0: r1 += 1\n",
    "    else:\n",
    "        for card in value:\n",
    "            assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "            potential_appendable_cards_data.append([\n",
    "                assetId,\n",
    "                rarity,\n",
    "                seasonYear,\n",
    "                birthdate,\n",
    "                bestFoot,\n",
    "                firstname,\n",
    "                lastname,\n",
    "                shirtNumber,\n",
    "                weight,\n",
    "                height\n",
    "            ])\n",
    "        r2 += 1\n",
    "        continue\n",
    "        \n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()\n",
    "        \n",
    "print(\"Players without valid elements: \", not_valid_elements)\n",
    "print(\"Players without results in players table: \", r0)\n",
    "print(\"These player can potentially be matched: \", not_valid_elements + r0, \" with a total no of rows: \", len(not_appended_cards_data_v2))\n",
    "print(\"******************\")\n",
    "print(\"Players (rows) that are matched, but already in cards table (no action required): \", duplicate_found_rows)\n",
    "print(\"******************\")\n",
    "print(\"Players that couldn't be matched, because there at least two players with same birthdate, weight & height: \", r2)\n",
    "print(\"with total rows that could still be matched with other methods: \", len(potential_appendable_cards_data))\n",
    "print(\"******************\")\n",
    "print(\"Players that are now matched: \", r1)\n",
    "print(\"with new added total rows of: \", len(cards_data_v2))\n",
    "print(\"******************\")\n",
    "print(\"At this point we matched from a total of \", len(cards_data) + len(cards_data_v2), \" rows.\")\n",
    "\n",
    "\n",
    "with open('./data/cleaned_cards_2.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(cards_data_v2)\n",
    "    \n",
    "with open('./data/cleaned_not_appended_cards_2.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(not_appended_cards_data_v2)\n",
    "    \n",
    "with open('./data/cleaned_potentially_appendable_cards_2.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(potential_appendable_cards_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a030904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert 2. Match cleaned_cards_2.csv data into db\n",
    "\n",
    "# connect to db\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# move data to public, because of access rights (ON CONFLICT clause is only available in PostgreSQL 9.5 and later)\n",
    "sql = '''COPY Card(assetID,rarity,seasonYear,birthDate,bestFoot,firstName,lastName,shirtNumber)\n",
    "FROM 'C:/Users/Public/cleaned_cards_2.csv'\n",
    "DELIMITER ','\n",
    "ENCODING 'UTF8'\n",
    "CSV HEADER;'''\n",
    "\n",
    "try:\n",
    "    cursor.execute(sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0858140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of players that are still not matched as cards:  95\n",
      "with a total of no of rows that are not matched:  9026\n"
     ]
    }
   ],
   "source": [
    "# create hash table for third matching\n",
    "potential_appendable_cards_dict = {}\n",
    "for card in potential_appendable_cards_data:\n",
    "    assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "    player_key = firstname + lastname + birthdate\n",
    "    if player_key in potential_appendable_cards_dict:\n",
    "        potential_appendable_cards_dict[player_key].append((assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height))\n",
    "    else:\n",
    "        potential_appendable_cards_dict[player_key] = [(assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height)]\n",
    "        \n",
    "print(\"No of players that are still not matched as cards: \", len(potential_appendable_cards_dict))\n",
    "print(\"with a total of no of rows that are not matched: \", len(potential_appendable_cards_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eaaa9654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found in total  71  matches.\n",
      "We added in total  70  matches with total rows of:  6612\n",
      "Duplicate rows:  56\n"
     ]
    }
   ],
   "source": [
    "# 3. Matching (95 Player, 9026 rows): Match cards with name\n",
    "# results of queries are always bigger than 1\n",
    "\n",
    "from Levenshtein import distance\n",
    "\n",
    "cards_data_v3 = [[\"assetID\",\"rarity\",\"seasonYear\",\"birthDate\",\"bestFoot\",\"firstName\",\"lastName\", \"shirtNumber\"]]\n",
    "\n",
    "new_cards_dict_v3 = dict(new_cards_dict) # to check for duplicates in play\n",
    "\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# helper\n",
    "matches = 0\n",
    "added_matches = 0\n",
    "duplicate_found_rows = 0\n",
    "\n",
    "for key, value in potential_appendable_cards_dict.items():\n",
    "    birthdate, firstname, lastname, weight, height = value[0][3], value[0][5], value[0][6], value[0][8], value[0][9]\n",
    "    cardFirstname, cardLastname = firstname.split(' ')[0], lastname.split(' ')[0]\n",
    "    cardName = cardFirstname + cardLastname\n",
    "    \n",
    "    # make sql statement (assumpiton: professional player, weight and height match)\n",
    "    query = \"SELECT * FROM Player WHERE birthdate = %s AND weightkg = %s AND heightcm = %s\"\n",
    "    cursor.execute(query, (birthdate, weight, height))\n",
    "    results = cursor.fetchall()\n",
    "    \n",
    "    for result in results:\n",
    "        # players table\n",
    "        playerFirstname, playerLastname = result[1].split(' ')[0], result[2].split(' ')[0]\n",
    "        playerName = playerFirstname + playerLastname\n",
    "        \n",
    "        # find Levenshtein distance between cards name and players name in Player table\n",
    "        lev_distance = distance(cardName, playerName)\n",
    "        \n",
    "        if lev_distance < 5:\n",
    "            matches += 1\n",
    "            temp_r1 = 0\n",
    "            for card in value:\n",
    "                assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "\n",
    "                # don't add duplicates\n",
    "                if assetId in new_cards_dict_v3:\n",
    "                    duplicate_found_rows += 1\n",
    "                else:\n",
    "                    cards_data_v3.append([\n",
    "                        assetId,\n",
    "                        rarity,\n",
    "                        seasonYear,\n",
    "                        birthdate, # birthdate must be correct, coz of query - foreign key constrain\n",
    "                        bestFoot,\n",
    "                        result[1], # use firstname from players table (source of truth) - foreign key constrain\n",
    "                        result[2], # use lastname from players table (source of truth) - foreign key constrain\n",
    "                        shirtNumber\n",
    "                    ])\n",
    "\n",
    "                    new_cards_dict_v3[assetId] = True\n",
    "                    temp_r1 += 1\n",
    "            if temp_r1 > 0: added_matches += 1\n",
    "    \n",
    "    \n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "with open('./data/cleaned_cards_3.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(cards_data_v3)\n",
    "    \n",
    "    \n",
    "print(\"We found in total \", matches, \" matches.\")\n",
    "print(\"We added in total \", added_matches, \" matches with total rows of: \", len(cards_data_v3))\n",
    "print(\"Duplicate rows: \", duplicate_found_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35cfa494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert 3. Match cleaned_cards_3.csv data into db\n",
    "\n",
    "# connect to db\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# move data to public, because of access rights (ON CONFLICT clause is only available in PostgreSQL 9.5 and later)\n",
    "sql = '''COPY Card(assetID,rarity,seasonYear,birthDate,bestFoot,firstName,lastName,shirtNumber)\n",
    "FROM 'C:/Users/Public/cleaned_cards_3.csv'\n",
    "DELIMITER ','\n",
    "ENCODING 'UTF8'\n",
    "CSV HEADER;'''\n",
    "\n",
    "try:\n",
    "    cursor.execute(sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8113bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of players that are not matched as cards:  3293\n",
      "with a total of no of rows that are not matched:  299998\n"
     ]
    }
   ],
   "source": [
    "# create hash table with not appended cards v2\n",
    "not_appended_cards_dict_v2 = {}\n",
    "for card in not_appended_cards_data_v2:\n",
    "    assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "    player_key = firstname + lastname + birthdate\n",
    "    if player_key in not_appended_cards_dict_v2:\n",
    "        not_appended_cards_dict_v2[player_key].append((assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height))\n",
    "    else:\n",
    "        not_appended_cards_dict_v2[player_key] = [(assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height)]\n",
    "        \n",
    "print(\"No of players that are not matched as cards: \", len(not_appended_cards_dict_v2))\n",
    "print(\"with a total of no of rows that are not matched: \", len(not_appended_cards_data_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "845f9b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found in total  1692  matches.\n",
      "We added in total  1692  matches with total rows of:  156761\n",
      "Duplicate rows:  0\n",
      "No results (no birthdate match):  22\n",
      "Still not matched data (rows)  143238\n"
     ]
    }
   ],
   "source": [
    "# 4. Matching (3293 Player, 299998 rows): Match cards with name\n",
    "\n",
    "cards_data_v4 = [[\"assetID\",\"rarity\",\"seasonYear\",\"birthDate\",\"bestFoot\",\"firstName\",\"lastName\", \"shirtNumber\"]]\n",
    "not_appended_cards_data_v3 = []\n",
    "new_cards_dict_v4 = dict(new_cards_dict_v3) # to check for duplicates in play\n",
    "\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# helper\n",
    "matches_v2 = 0\n",
    "added_matches_v2 = 0\n",
    "duplicate_found_rows_v2 = 0\n",
    "no_results = 0\n",
    "\n",
    "for key, value in not_appended_cards_dict_v2.items():\n",
    "    birthdate, firstname, lastname = value[0][3], value[0][5], value[0][6]\n",
    "    cardFirstname, cardLastname = firstname.split(' ')[0], lastname.split(' ')[0]\n",
    "    cardName = cardFirstname + cardLastname\n",
    "    \n",
    "    # make sql statement (assumpiton: professional player, weight and height match)\n",
    "    query = \"SELECT * FROM Player WHERE birthdate = %s\"\n",
    "    cursor.execute(query, (birthdate,))\n",
    "    results = cursor.fetchall()\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        for card in value:\n",
    "            assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "            not_appended_cards_data_v3.append([\n",
    "                assetId,\n",
    "                rarity,\n",
    "                seasonYear,\n",
    "                birthdate,\n",
    "                bestFoot,\n",
    "                firstname,\n",
    "                lastname,\n",
    "                shirtNumber,\n",
    "                weight,\n",
    "                height\n",
    "            ])\n",
    "        no_results += 1\n",
    "        continue\n",
    "        \n",
    "    temp_r2 = 0\n",
    "        \n",
    "    for result in results:\n",
    "        # players table\n",
    "        playerFirstname, playerLastname = result[1].split(' ')[0], result[2].split(' ')[0]\n",
    "        playerName = playerFirstname + playerLastname\n",
    "        \n",
    "        # find Levenshtein distance between cards name and players name in Player table\n",
    "        lev_distance = distance(cardName, playerName)\n",
    "        \n",
    "        # very close match (weight/height problem solved)\n",
    "        if lev_distance < 3:\n",
    "            matches_v2 += 1\n",
    "            temp_r1 = 0\n",
    "            for card in value:\n",
    "                assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "\n",
    "                # don't add duplicates\n",
    "                if assetId in new_cards_dict_v4:\n",
    "                    duplicate_found_rows_v2 += 1\n",
    "                else:\n",
    "                    cards_data_v4.append([\n",
    "                        assetId,\n",
    "                        rarity,\n",
    "                        seasonYear,\n",
    "                        birthdate, # birthdate must be correct, coz of query - foreign key constrain\n",
    "                        bestFoot,\n",
    "                        result[1], # use firstname from players table (source of truth) - foreign key constrain\n",
    "                        result[2], # use lastname from players table (source of truth) - foreign key constrain\n",
    "                        shirtNumber\n",
    "                    ])\n",
    "\n",
    "                    new_cards_dict_v4[assetId] = True\n",
    "                    temp_r1 += 1\n",
    "                    temp_r2 += 1\n",
    "            if temp_r1 > 0: added_matches_v2 += 1\n",
    "    \n",
    "    # card wasn't matched or duplicate\n",
    "    if temp_r2 == 0: \n",
    "        for card in value:\n",
    "            assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "            not_appended_cards_data_v3.append([\n",
    "                assetId,\n",
    "                rarity,\n",
    "                seasonYear,\n",
    "                birthdate,\n",
    "                bestFoot,\n",
    "                firstname,\n",
    "                lastname,\n",
    "                shirtNumber,\n",
    "                weight,\n",
    "                height\n",
    "            ])\n",
    "                \n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "with open('./data/cleaned_cards_4.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(cards_data_v4)\n",
    "    \n",
    "with open('./data/cleaned_not_appended_cards_3.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(not_appended_cards_data_v3)\n",
    "    \n",
    "    \n",
    "print(\"We found in total \", matches_v2, \" matches.\")\n",
    "print(\"We added in total \", added_matches_v2, \" matches with total rows of: \", len(cards_data_v4))\n",
    "print(\"Duplicate rows: \", duplicate_found_rows_v2)\n",
    "print(\"No results (no birthdate match): \", no_results)\n",
    "print(\"Still not matched data (rows) \", len(not_appended_cards_data_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cff436c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert 4. Match cleaned_cards_4.csv data into db\n",
    "\n",
    "# connect to db\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# move data to public, because of access rights (ON CONFLICT clause is only available in PostgreSQL 9.5 and later)\n",
    "sql = '''COPY Card(assetID,rarity,seasonYear,birthDate,bestFoot,firstName,lastName,shirtNumber)\n",
    "FROM 'C:/Users/Public/cleaned_cards_4.csv'\n",
    "DELIMITER ','\n",
    "ENCODING 'UTF8'\n",
    "CSV HEADER;'''\n",
    "\n",
    "try:\n",
    "    cursor.execute(sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b977e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of players that are not matched as cards:  1601\n",
      "with a total of no of rows that are not matched:  143238\n"
     ]
    }
   ],
   "source": [
    "# create hash table with not appended cards v3\n",
    "not_appended_cards_dict_v3 = {}\n",
    "for card in not_appended_cards_data_v3:\n",
    "    assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "    player_key = firstname + lastname + birthdate\n",
    "    if player_key in not_appended_cards_dict_v3:\n",
    "        not_appended_cards_dict_v3[player_key].append((assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height))\n",
    "    else:\n",
    "        not_appended_cards_dict_v3[player_key] = [(assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height)]\n",
    "        \n",
    "print(\"No of players that are not matched as cards: \", len(not_appended_cards_dict_v3))\n",
    "print(\"with a total of no of rows that are not matched: \", len(not_appended_cards_data_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfd25112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found in total  892  matches.\n",
      "We added in total  861  matches with total rows of:  80615\n",
      "Duplicate rows:  2427\n",
      "No results (no birthdate match):  22\n",
      "Still not matched data (rows)  62624\n"
     ]
    }
   ],
   "source": [
    "# 5. Matching (1601 Player, 143238 rows): Match cards with firstname or lastname exact match\n",
    "\n",
    "cards_data_v5 = [[\"assetID\",\"rarity\",\"seasonYear\",\"birthDate\",\"bestFoot\",\"firstName\",\"lastName\", \"shirtNumber\"]]\n",
    "not_appended_cards_data_v4 = []\n",
    "new_cards_dict_v5 = dict(new_cards_dict_v4) # to check for duplicates in play\n",
    "\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# helper\n",
    "matches_v2 = 0\n",
    "added_matches_v2 = 0\n",
    "duplicate_found_rows_v2 = 0\n",
    "no_results = 0\n",
    "\n",
    "for key, value in not_appended_cards_dict_v3.items():\n",
    "    birthdate, firstname, lastname = value[0][3], value[0][5], value[0][6]\n",
    "    cardFirstname, cardLastname = firstname.split(' ')[0], lastname.split(' ')[0]\n",
    "    \n",
    "    # make sql statement (assumpiton: professional player, weight and height match)\n",
    "    query = \"SELECT * FROM Player WHERE birthdate = %s\"\n",
    "    cursor.execute(query, (birthdate,))\n",
    "    results = cursor.fetchall()\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        for card in value:\n",
    "            assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "            not_appended_cards_data_v4.append([\n",
    "                assetId,\n",
    "                rarity,\n",
    "                seasonYear,\n",
    "                birthdate,\n",
    "                bestFoot,\n",
    "                firstname,\n",
    "                lastname,\n",
    "                shirtNumber,\n",
    "                weight,\n",
    "                height\n",
    "            ])\n",
    "        no_results += 1\n",
    "        continue\n",
    "        \n",
    "    temp_r2 = 0\n",
    "        \n",
    "    for result in results:\n",
    "        # players table\n",
    "        playerFirstname, playerLastname = result[1].split(' ')[0], result[2].split(' ')[0]\n",
    "        \n",
    "        # find Levenshtein distance between firstname and lastname seperated\n",
    "        lev_distance_firstname = distance(cardFirstname, playerFirstname)\n",
    "        lev_distance_lastname = distance(cardLastname, playerLastname)\n",
    "\n",
    "        \n",
    "        # exact match either firstname or lastname\n",
    "        if lev_distance_firstname == 0 or lev_distance_lastname == 0:\n",
    "            matches_v2 += 1\n",
    "            temp_r1 = 0\n",
    "            for card in value:\n",
    "                assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "\n",
    "                # don't add duplicates\n",
    "                if assetId in new_cards_dict_v5:\n",
    "                    duplicate_found_rows_v2 += 1\n",
    "                else:\n",
    "                    cards_data_v5.append([\n",
    "                        assetId,\n",
    "                        rarity,\n",
    "                        seasonYear,\n",
    "                        birthdate, # birthdate must be correct, coz of query - foreign key constrain\n",
    "                        bestFoot,\n",
    "                        result[1], # use firstname from players table (source of truth) - foreign key constrain\n",
    "                        result[2], # use lastname from players table (source of truth) - foreign key constrain\n",
    "                        shirtNumber\n",
    "                    ])\n",
    "\n",
    "                    new_cards_dict_v5[assetId] = True\n",
    "                    temp_r1 += 1\n",
    "                    temp_r2 += 1\n",
    "            if temp_r1 > 0: added_matches_v2 += 1\n",
    "    \n",
    "    # card wasn't matched or duplicate\n",
    "    if temp_r2 == 0: \n",
    "        for card in value:\n",
    "            assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "            not_appended_cards_data_v4.append([\n",
    "                assetId,\n",
    "                rarity,\n",
    "                seasonYear,\n",
    "                birthdate,\n",
    "                bestFoot,\n",
    "                firstname,\n",
    "                lastname,\n",
    "                shirtNumber,\n",
    "                weight,\n",
    "                height\n",
    "            ])\n",
    "                \n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "with open('./data/cleaned_cards_5.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(cards_data_v5)\n",
    "    \n",
    "with open('./data/cleaned_not_appended_cards_4.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(not_appended_cards_data_v4)\n",
    "    \n",
    "    \n",
    "print(\"We found in total \", matches_v2, \" matches.\")\n",
    "print(\"We added in total \", added_matches_v2, \" matches with total rows of: \", len(cards_data_v5))\n",
    "print(\"Duplicate rows: \", duplicate_found_rows_v2)\n",
    "print(\"No results (no birthdate match): \", no_results)\n",
    "print(\"Still not matched data (rows) \", len(not_appended_cards_data_v4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32b99e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert 5. Match cleaned_cards_5.csv data into db\n",
    "\n",
    "# connect to db\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# move data to public, because of access rights (ON CONFLICT clause is only available in PostgreSQL 9.5 and later)\n",
    "sql = '''COPY Card(assetID,rarity,seasonYear,birthDate,bestFoot,firstName,lastName,shirtNumber)\n",
    "FROM 'C:/Users/Public/cleaned_cards_5.csv'\n",
    "DELIMITER ','\n",
    "ENCODING 'UTF8'\n",
    "CSV HEADER;'''\n",
    "\n",
    "try:\n",
    "    cursor.execute(sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "838d8318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of players that are not matched as cards:  740\n",
      "with a total of no of rows that are not matched:  62624\n"
     ]
    }
   ],
   "source": [
    "# create hash table with not appended cards v4\n",
    "not_appended_cards_dict_v4 = {}\n",
    "for card in not_appended_cards_data_v4:\n",
    "    assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height = card[0], card[1], card[2], card[3], card[4], card[5], card[6], card[7], card[8], card[9]\n",
    "    player_key = firstname + lastname + birthdate\n",
    "    if player_key in not_appended_cards_dict_v4:\n",
    "        not_appended_cards_dict_v4[player_key].append((assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height))\n",
    "    else:\n",
    "        not_appended_cards_dict_v4[player_key] = [(assetId, rarity, seasonYear, birthdate, bestFoot, firstname, lastname, shirtNumber, weight, height)]\n",
    "        \n",
    "print(\"No of players that are not matched as cards: \", len(not_appended_cards_dict_v4))\n",
    "print(\"with a total of no of rows that are not matched: \", len(not_appended_cards_data_v4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1d738b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean raw_sorare_all_nfts.json data & convert to csv\n",
    "with open('./data/raw_sorare_all_nfts.json', encoding=\"utf-8\") as file:\n",
    "    nfts = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de1d7c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All nft rows:  1380900\n",
      "Inserted nfts (rows):  898150\n",
      "Not inserted nfts (rows):  482751\n",
      "Inserted owHistory rows:  1850694\n"
     ]
    }
   ],
   "source": [
    "nfts_data = [[\"nftID\",\"assetID\",\"slug\",\"currentOwnerAddress\"]]\n",
    "ownershipHistory_data = [[\"address\",\"transferDate\",\"priceEuro\",\"transferType\", \"blockchain\", \"nftID\"]]\n",
    "new_cards_dict_v6 = dict(new_cards_dict_v5)\n",
    "oHistory_dict = {}\n",
    "\n",
    "# helper\n",
    "not_inserted_nfts = 0\n",
    "\n",
    "for nft in nfts:\n",
    "    \n",
    "    # check if there is an owner address, don't insert\n",
    "    if nft is not None and \"owner\" in nft and nft[\"owner\"] is not None and \"address\" in nft[\"owner\"] and nft[\"owner\"][\"address\"] is not None:\n",
    "        currentOwnerAddress = nft[\"owner\"][\"address\"]\n",
    "    else:\n",
    "        not_inserted_nfts += 1\n",
    "        continue\n",
    "\n",
    "    nftId, assetId, slug, ownershipHistory = nft[\"id\"], nft[\"assetId\"], nft[\"slug\"], nft[\"ownershipHistory\"]\n",
    "    \n",
    "    # foreign key constraint\n",
    "    if assetId in new_cards_dict_v6:\n",
    "        nfts_data.append([nftId, assetId, slug, currentOwnerAddress])\n",
    "        \n",
    "        # insert ownershiphistory\n",
    "        if len(ownershipHistory) > 0:\n",
    "            for owHistory in ownershipHistory:\n",
    "                address, transferDate, priceEuro, transferType, blockchain = owHistory[\"address\"], owHistory[\"from\"], owHistory[\"priceFiat\"][\"eur\"], owHistory[\"transferType\"], owHistory[\"blockchain\"]\n",
    "                \n",
    "                # don't add 0 trx & primary key duplicate check\n",
    "                key = address + transferDate\n",
    "                if priceEuro > 0 and (key not in oHistory_dict):\n",
    "                    ownershipHistory_data.append([address, transferDate, priceEuro, transferType, blockchain, nftId])\n",
    "                    oHistory_dict[key] = True\n",
    "    else:\n",
    "        not_inserted_nfts += 1\n",
    "        \n",
    "print(\"All nft rows: \", len(nfts))\n",
    "print(\"Inserted nfts (rows): \", len(nfts_data))\n",
    "print(\"Not inserted nfts (rows): \", not_inserted_nfts)\n",
    "print(\"Inserted owHistory rows: \", len(ownershipHistory_data))\n",
    "\n",
    "with open('./data/cleaned_nfts.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(nfts_data)\n",
    "    \n",
    "with open('./data/cleaned_owHistory.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(ownershipHistory_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "809abb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert cleaned_nfts.csv data into db\n",
    "\n",
    "# connect to db\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# move data to public, because of access rights (ON CONFLICT clause is only available in PostgreSQL 9.5 and later)\n",
    "sql = '''COPY NFT(nftID,assetID,slug,currentOwnerAddress)\n",
    "FROM 'C:/Users/Public/cleaned_nfts.csv'\n",
    "DELIMITER ','\n",
    "ENCODING 'UTF8'\n",
    "CSV HEADER;'''\n",
    "\n",
    "try:\n",
    "    cursor.execute(sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1044710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert cleaned_owHistory.csv data into db\n",
    "\n",
    "# connect to db\n",
    "connection = psycopg2.connect(\"dbname=dbproject-sorare user=postgres password=Test1234\") # use your user & password\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# move data to public, because of access rights (ON CONFLICT clause is only available in PostgreSQL 9.5 and later)\n",
    "sql = '''COPY OwnershipHistory(address,transferDate,priceEuro,transferType, blockchain, nftID)\n",
    "FROM 'C:/Users/Public/cleaned_owHistory.csv'\n",
    "DELIMITER ','\n",
    "ENCODING 'UTF8'\n",
    "CSV HEADER;'''\n",
    "\n",
    "try:\n",
    "    cursor.execute(sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# close connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
