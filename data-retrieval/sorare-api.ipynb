{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4a6ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import bcrypt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication Sorare API with Postman\n",
    "\n",
    "salt = b\"xxx\"\n",
    "password = b\"xxx\"\n",
    "hashed_password = bcrypt.hashpw(password, salt)\n",
    "\n",
    "\"\"\"\n",
    "***Query to https://api.sorare.com/graphql****\n",
    "\n",
    "mutation SignInMutation($input: signInInput!) {\n",
    "  signIn(input: $input) {\n",
    "    currentUser {\n",
    "      slug\n",
    "      jwtToken(aud: \"databases-project\") {\n",
    "        token\n",
    "        expiredAt\n",
    "      }\n",
    "    }\n",
    "    errors {\n",
    "      message\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "***GraphQL Variables****\n",
    "{\n",
    "  \"input\": {\n",
    "    \"email\": \"xxx\",\n",
    "    \"password\": \"hashed_password\"\n",
    "  }\n",
    "}\n",
    "\n",
    "***Response****\n",
    "{\n",
    "    \"jwt\": \"token\"\n",
    "    \"expiredAt\": \"2022-12-04T10:36:32Z\"\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a62541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorare data from https://api.sorare.com/graphq (access via VPN, CH not allowed)\n",
    "# Playground: https://api.sorare.com/graphql/playground\n",
    "\n",
    "url = 'https://api.sorare.com/graphql'\n",
    "headers = {\n",
    "  'Content-Type': 'application/json',\n",
    "  'Authorization': 'Bearer ourJWT', # use jwt\n",
    "  'JWT-AUD': 'databases-project'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326dad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fetch all football nfts with pagination (Result: see \"./mock-data/raw_all_nfts.json\")\n",
    "\n",
    "# create GraphQL query helper to fetch all nfts\n",
    "def createAllNftsQuery(endCursor):\n",
    "    qStart = \"{tokens{allNfts(last: 50, sport: FOOTBALL, after: \"\n",
    "    if endCursor == \"null\":\n",
    "        qMiddle = \"null\"\n",
    "    else:\n",
    "        qMiddle = f'\"{endCursor}\"'\n",
    "    qEnd = \"\"\") {\n",
    "          nodes {\n",
    "            assetId\n",
    "            id\n",
    "            slug\n",
    "            owner {\n",
    "              address\n",
    "              from\n",
    "            }\n",
    "            ownershipHistory {\n",
    "              address\n",
    "              blockchain\n",
    "              from\n",
    "              priceFiat {\n",
    "                eur\n",
    "              }\n",
    "              priceWei\n",
    "              transferType\n",
    "            }\n",
    "          }\n",
    "          pageInfo {\n",
    "            endCursor\n",
    "            hasNextPage\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\"\"\"\n",
    "    \n",
    "    return qStart + qMiddle + qEnd\n",
    "\n",
    "\n",
    "\n",
    "hasNextPage = True # first result has a next page\n",
    "endCursor = \"null\" # first endCuror must be null (in string format)\n",
    "namingCount = 1 # to create seperate .json files for every 50 entries  \n",
    "\n",
    "# continue until last page\n",
    "while hasNextPage:\n",
    "    time.sleep(3) # wait at least 3 seconds, API restriction (20x per Minute)\n",
    "    query = createAllNftsQuery(endCursor) # with endCursor\n",
    "    \n",
    "    # request\n",
    "    response = requests.post(url, headers=headers, json={'query': query})\n",
    "    jsonData = response.json()\n",
    "    endCursor = jsonData['data']['tokens']['allNfts']['pageInfo']['endCursor'] # set new endCursor\n",
    "    hasNextPage = jsonData['data']['tokens']['allNfts']['pageInfo']['hasNextPage'] # set new hasNextPage\n",
    "    nfts = jsonData['data']['tokens']['allNfts']['nodes'] # actual nft data\n",
    "\n",
    "    nfts_data = []\n",
    "    for nft in nfts:\n",
    "        nfts_data.append(nft)\n",
    "    \n",
    "    # create single nft file with 50 entries (restriction entries per page)\n",
    "    with open(f\"../data/sorare_nfts/nfts_{namingCount}.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(nfts_data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    namingCount += 1\n",
    "    \n",
    "\n",
    "# 1.2 Merge all nfts into one single file\n",
    "files = [f\"../data/sorare_nfts/nfts_{i}.json\" for i in range(1, 27620)] # 27619 files; nfts_1 ... nfts_27619\n",
    "\n",
    "# credits: https://stackoverflow.com/questions/57422734/how-to-merge-multiple-json-files-into-one-file-in-python; Akaisteph7\n",
    "def mergeJsonFiles(files, filename):\n",
    "    result = list()\n",
    "    for f1 in files:\n",
    "        with open(f1, 'r') as infile:\n",
    "            result.extend(json.load(infile))\n",
    "\n",
    "    with open(filename, 'w') as output_file:\n",
    "        json.dump(result, output_file)\n",
    "\n",
    "mergeJsonFiles(files, '../data/sorare_all_nfts.json') # merge all files into one single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af127f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Fetch all cards according to nfts fetched previously (Result: see \"./mock-data/raw_all_cards.json\")\n",
    "\n",
    "# create GraphQL query helper to fetch all cards\n",
    "def createAllCardsQuery(slugs):\n",
    "    qStart = \"{allCards(slugs: [\"\n",
    "    # insert all slugs\n",
    "    qMiddle = \"\"\n",
    "    for i in slugs:\n",
    "        qMiddle += f'\"{i}\",'\n",
    "    \n",
    "    qEnd = \"\"\"]\n",
    "      ) {\n",
    "        nodes {\n",
    "          assetId\n",
    "          birthTxHash\n",
    "          blockchainId\n",
    "          name\n",
    "          owner {\n",
    "            address\n",
    "            from\n",
    "          }\n",
    "          ownerSince\n",
    "          player {\n",
    "            age\n",
    "            birthDate\n",
    "            bestFoot\n",
    "            firstName\n",
    "            lastName\n",
    "            displayName\n",
    "            height\n",
    "            weight\n",
    "            slug\n",
    "            shirtNumber\n",
    "            activeClub {\n",
    "              name\n",
    "              slug\n",
    "            }\n",
    "            lastClub {\n",
    "              name\n",
    "              slug\n",
    "            }\n",
    "          }\n",
    "          rarity\n",
    "          season {\n",
    "            id\n",
    "            name\n",
    "            startYear\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    return qStart + qMiddle + qEnd\n",
    "\n",
    "namingCount = 1\n",
    "\n",
    "# iterate over all single nft files (50 entries per file)\n",
    "for i in range(namingCount, 27620):\n",
    "    time.sleep(3) # wait at least 3 seconds, API restriction (20x per Minute)\n",
    "    \n",
    "    with open(f'../data/sorare_nfts/nfts_{i}.json') as f: # open single nft file and load data (50 entries)\n",
    "        nfts = json.load(f)\n",
    "    \n",
    "    # create cards query with all the slugs per file\n",
    "    slugs = [nft[\"slug\"] for nft in nfts]\n",
    "    query = createAllCardsQuery(slugs)\n",
    "    \n",
    "    # request f√ºr cards\n",
    "    response = requests.post(url, headers=headers, json={'query': query})\n",
    "    jsonData = response.json()\n",
    "    cards = jsonData['data']['allCards']['nodes'] # actual cards data\n",
    "    \n",
    "    cards_data = []\n",
    "    for card in cards:\n",
    "        cards_data.append(card)\n",
    "        \n",
    "    # create single card file with 50 entries \n",
    "    with open(f\"../data/sorare_cards/cards_{namingCount}.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(cards_data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    namingCount += 1\n",
    "\n",
    "    \n",
    "# 2.2 Merge all cards into one single file\n",
    "files = [f\"../data/sorare_cards/cards_{i}.json\" for i in range(1, tbd)] # tbd files; cards_1 ... cards_tbd\n",
    "mergeJsonFiles(files, '../data/sorare_all_cards.json') # merge all files into one single file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
